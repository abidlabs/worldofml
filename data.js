/*
The variable 'content' stores primary information about all topics, including key/slug (required), video_url (required), title, etc.
*/

var content = 
{
	"exponential_families_definition":{
		"title":"Exponential Families",
		"video_url":"https://www.youtube.com/watch?v=_aNk4QKi2_o"
	},
	"EM":{
		"title":"Expectation-Maximization Algorithm",
		"video_url":"https://www.youtube.com/watch?v=AnbiNaVp3eQ"
	},
	"dirichlet_distribution":{
		"title":"Dirichlet Distribution",
		"video_url":"https://www.youtube.com/watch?v=nfBNOWv1pgE"
	},
	"Empirical Bayes":{
		"title":
		"video_url":
	},
	"classification_tree":{
		"title":"Classification Tree",
		"video_url":"https://www.youtube.com/watch?v=p17C9q2M00Q"
	},
	""
	"vc_dimension":{
		"title":"VC Dimension",
		"video_url":"https://www.youtube.com/watch?v=puDzy2XmR5c",
	},
	"empirical_risk_minimization":{
		"title":"Empirical Risk Minimization",
		"video_url":"https://www.youtube.com/watch?v=5adNQvSlF50"
	},
	"causal_inference":{
		"title":"Causal Inference",
		"video_url":"https://www.youtube.com/watch?v=tO99T1GQ6SY",
	},
	"gaussian_mixture_model"{
		"title":"Gaussian Mixture Model (GMM)",
		"video_url":"https://www.youtube.com/watch?v=Rkl30Fr2S38"
	},
	"bias_variance_tradeoff":{
		"title":"Bias-Variance Tradeoff",
		"video_url":"https://www.youtube.com/watch?v=C3nIFH649wY"
	},
	"bagging":{
		"title":"Bootstrap Aggregation (Bagging)",
		"video_url":"https://www.youtube.com/watch?v=5Lu1eTiX7qM&t=39s"
	},
	"random_forests":{
		"title":"Random Forests",
		"video_url":"https://www.youtube.com/watch?v=o7iDkcpOr_g"
	},
	"one_vs_all":{
		"title":"One vs. Rest (OVR) Multiclass Classification",
		"video_url":"https://www.youtube.com/watch?v=TrcG0h5tPO8",
	},
	"intro_ml":{
		"title":"Introduction to Machine Learning",
		"video_url":"youtube.com",
		"description":"This video serves as an introduction both to machine learning as well as how to use this site",
	},
	"kl_divergence": {
		"title":"K-L Divergence (Relative Entropy)",
		"video_url":"https://www.youtube.com/watch?v=iYYX0M4sp1g",
		"description":"By considering the inefficiency due to using the wrong probability distribution to design a code using Shannon coding, we arrive at the relative entropy."
	},
	"information_entropy": {
		"title":"Entropy (Information Theory)",
		"video_url":"https://www.youtube.com/watch?v=LodZWzrbayY",		
	},
	// "information_entropy":{"video_url":""},
	"k_means":{
		"title":"K-means Clustering",
		"video_url":"https://www.youtube.com/watch?v=_aWzGGNrcic",
		"description":"The K-means algorithm starts by placing K points (centroids) at random locations in space. We then perform the following steps iteratively: (1) for each instance, we assign it to a cluster with the nearest centroid, and (2) we move each centroid to the mean of the instances assigned to it. The algorithm continues until no instances change cluster membership."
	},
	"spectral_clustering":{
		"title":"Spectral Clustering",
		"video_url":"https://www.youtube.com/watch?v=P-LEH-AFovE",
		"description":'In multivariate statistics and the clustering of data, spectral clustering techniques make use of the spectrum (eigenvalues) of the similarity matrix of the data to perform dimensionality reduction before clustering in fewer dimensions. The similarity matrix is provided as an input and consists of a quantitative assessment of the relative similarity of each pair of points in the dataset. In application to image segmentation, spectral clustering is known as segmentation-based object categorization.'
	},
	"monte_carlo_method":{
		"title":"Monte Carlo Method",
		"video_url":"https://www.youtube.com/watch?v=5nM5e2_1OQ0",
	},
	"mcmc":{
		"title":"Markov Chain Monte Carlo (MCMC)",
		"video_url":"https://www.youtube.com/watch?v=12eZWG0Z5gY",
	},
	"markov_chain":{
		"title":"Markov Chains",
		"video_url":"https://www.youtube.com/watch?v=nnssRe5DewE",
	},
	"importance_sampling":{
		"title":"Importance Sampling",
		"video_url":"https://www.youtube.com/watch?v=S3LAOZxGcnk",
		"description":"In statistics, importance sampling is a general technique for estimating properties of a particular distribution, while only having samples generated from a different distribution than the distribution of interest."
	}
}